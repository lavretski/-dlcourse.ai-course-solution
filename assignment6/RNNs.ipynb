{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEWxywgHfqcs"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8sVtGHmA9aBM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "ltnsuOLPghDc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiA2dGmgF1rW",
        "outputId": "3d739e0d-8600-41cd-95a0-aff3cb4a91d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstS4NO0L97c",
        "outputId": "ed067096-7d44-48a2-ad5f-a4aa1f9418a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ]
        }
      ],
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTai8Ta0lgwL",
        "outputId": "35beb838-c4e9-413b-decc-f614bb81f0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCjwwDs6Zq9x",
        "outputId": "21f73587-48f5-4480-d7f8-6d10a9e2753d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words in train = 45441. Tags = {'PRT', 'ADP', 'VERB', 'X', 'NOUN', 'ADJ', 'ADV', 'DET', 'NUM', 'PRON', '.', 'CONJ'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PRT': 1,\n",
              " 'ADP': 2,\n",
              " 'VERB': 3,\n",
              " 'X': 4,\n",
              " 'NOUN': 5,\n",
              " 'ADJ': 6,\n",
              " 'ADV': 7,\n",
              " 'DET': 8,\n",
              " 'NUM': 9,\n",
              " 'PRON': 10,\n",
              " '.': 11,\n",
              " 'CONJ': 12,\n",
              " '<pad>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))\n",
        "tag2ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "URC1B2nvPGFt",
        "outputId": "15266366-cace-4bbe-cc6b-d014f4cdb931"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rWmSToIaeAo"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjz_Rk0bbMyH"
      },
      "outputs": [],
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "metadata": {
        "id": "CWvBn4X8np1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XCuxEBVbOY_"
      },
      "outputs": [],
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data, backoff = bigram_tagger)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RtRbz1SwgEqc"
      },
      "outputs": [],
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DhsTKZalfih6"
      },
      "outputs": [],
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XsRII5kW5x",
        "outputId": "463840d3-f13d-45d1-d49c-3c7482c99c53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_batch[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuCh67TIPPxR",
        "outputId": "fdd69ef1-b37b-498e-c84a-4f5351216c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  5.,  7.,  2.,  5.,  6.,  2.,  5.,  7.,  5.,  6., 10., 11.,\n",
              "        6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "        0.,  0.,  0.,  0.,  0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WVEHju54d68T"
      },
      "outputs": [],
      "source": [
        "class RNN_Vanilla(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.tagset_size = tagset_size\n",
        "        self.word_emb_dim = word_emb_dim\n",
        "        self.Embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.Wxhh = nn.Linear(word_emb_dim+lstm_hidden_dim, lstm_hidden_dim)\n",
        "        self.Tanh = nn.Tanh()\n",
        "        self.Why = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        sequence_size = len(inputs)\n",
        "        batch_size = inputs[0].size()[0]\n",
        "        result = torch.zeros(sequence_size, batch_size, self.tagset_size).to(device)\n",
        "        h = torch.zeros(batch_size, self.lstm_hidden_dim).to(device)\n",
        "        for i in range(sequence_size):\n",
        "            h = self.Tanh(self.Wxhh(torch.cat((h, self.Embedding(inputs[i])), dim=1)))\n",
        "            y = self.Why(h)\n",
        "            result[i] = y\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.Embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        output, (hn, cn) = self.lstm(self.Embedding(inputs))\n",
        "        res = self.relu(output)\n",
        "        res = self.fc(res)\n",
        "        return res"
      ],
      "metadata": {
        "id": "uqLiGwoDpfkS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbrxsZ2mehWB"
      },
      "outputs": [],
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").to(device)\n",
        "\n",
        "X_batch, y_batch = torch.Tensor(X_batch).to(device).long(), torch.Tensor(y_batch).to(device).long()\n",
        "\n",
        "logits = model(X_batch)\n",
        "logits.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMUyUm1hgpe3"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "c = 0\n",
        "for a, b in zip(logits, y_batch):\n",
        "    c+=criterion(a, b)\n",
        "print(c/len(logits))\n",
        "correct_samples = 0\n",
        "total_samples = 0\n",
        "for a, b in zip(logits, y_batch):\n",
        "    print(a, b)\n",
        "    print(indices)\n",
        "    _, indices = torch.max(a, 1)\n",
        "    correct_samples += torch.sum(indices == b)\n",
        "    total_samples += b.shape[0]\n",
        "float(correct_samples) / total_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FprPQ0gllo7b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = torch.Tensor(X_batch).to(device).long(), torch.Tensor(y_batch).to(device).long()\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = 0\n",
        "                for prediction, y in zip(logits, y_batch):\n",
        "                    loss += criterion(prediction, y)\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                cur_correct_count, cur_sum_count = 0, 0\n",
        "                for prediction, y in zip(logits, y_batch):\n",
        "                    _, indices = torch.max(prediction, 1)\n",
        "                    indices = indices * (y > 0)\n",
        "                    cur_correct_count += torch.sum(indices == y) - torch.sum(y == 0)\n",
        "                    cur_sum_count += torch.count_nonzero(y)\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqfbeh1ltEYa"
      },
      "outputs": [],
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind),\n",
        "    lstm_layers_count = 3\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98wr38_rw55D"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 0)\n",
        "fit(model, criterion, optimizer, train_data=(X_test, y_test), epochs_count=1,\n",
        "    batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKZNBIGfqc1"
      },
      "outputs": [],
      "source": [
        "class BidirectionalLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.Embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, lstm_layers_count, bidirectional = True)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim*2, tagset_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        output, (hn, cn) = self.lstm(self.Embedding(inputs))\n",
        "        res = self.relu(output)\n",
        "        res = self.fc(res)\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BidirectionalLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind),\n",
        "    lstm_layers_count = 2\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.Tensor(X_batch).long(), torch.Tensor(y_batch).long()\n",
        "\n",
        "logits = model(X_batch)\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "r08zKjKMeGfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = BidirectionalLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind),\n",
        "    lstm_layers_count = 3\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=3,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "metadata": {
        "id": "wA6mz3ClxKU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "VvEMnMLFxKU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uZpY_Q1xZ18h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fa7d19-c05f-415c-bf1f-17998d6025d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VsCstxiO03oT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171d92f7-04da-4a35-ad69-5286143f3ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45441, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LxaRBpQd0pat"
      },
      "outputs": [],
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.Embedding = nn.Embedding.from_pretrained(torch.Tensor(embeddings))\n",
        "        self.lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, lstm_layers_count)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        output, (hn, cn) = self.lstm(self.Embedding(inputs))\n",
        "        res = self.relu(output)\n",
        "        res = self.fc(res)\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalLSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.Embedding = nn.Embedding.from_pretrained(torch.Tensor(embeddings))\n",
        "        self.lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, lstm_layers_count, bidirectional = True)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim*2, tagset_size)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        output, (hn, cn) = self.lstm(self.Embedding(inputs))\n",
        "        res = self.relu(output)\n",
        "        res = self.fc(res)\n",
        "        return res"
      ],
      "metadata": {
        "id": "Jz8rS4q8ybhW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EBtI6BDE-Fc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7457495e-cf53-4abf-de7c-025f735c5cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 10] Train: Loss = 60.85276, Accuracy = 70.11%: 100%|██████████| 572/572 [00:15<00:00, 36.93it/s]\n",
            "[1 / 10]   Val: Loss = 37.07560, Accuracy = 88.79%: 100%|██████████| 13/13 [00:00<00:00, 28.96it/s]\n",
            "[2 / 10] Train: Loss = 16.50399, Accuracy = 92.44%: 100%|██████████| 572/572 [00:13<00:00, 42.83it/s]\n",
            "[2 / 10]   Val: Loss = 19.86061, Accuracy = 93.82%: 100%|██████████| 13/13 [00:00<00:00, 29.43it/s]\n",
            "[3 / 10] Train: Loss = 10.49789, Accuracy = 94.86%: 100%|██████████| 572/572 [00:13<00:00, 40.90it/s]\n",
            "[3 / 10]   Val: Loss = 16.66995, Accuracy = 94.76%: 100%|██████████| 13/13 [00:00<00:00, 29.44it/s]\n",
            "[4 / 10] Train: Loss = 7.88656, Accuracy = 95.84%: 100%|██████████| 572/572 [00:13<00:00, 42.92it/s]\n",
            "[4 / 10]   Val: Loss = 15.36967, Accuracy = 95.31%: 100%|██████████| 13/13 [00:00<00:00, 24.56it/s]\n",
            "[5 / 10] Train: Loss = 6.52888, Accuracy = 96.38%: 100%|██████████| 572/572 [00:13<00:00, 41.39it/s]\n",
            "[5 / 10]   Val: Loss = 13.07044, Accuracy = 95.75%: 100%|██████████| 13/13 [00:00<00:00, 29.09it/s]\n",
            "[6 / 10] Train: Loss = 5.58284, Accuracy = 96.76%: 100%|██████████| 572/572 [00:13<00:00, 43.46it/s]\n",
            "[6 / 10]   Val: Loss = 13.17934, Accuracy = 95.92%: 100%|██████████| 13/13 [00:00<00:00, 29.95it/s]\n",
            "[7 / 10] Train: Loss = 5.01174, Accuracy = 96.99%: 100%|██████████| 572/572 [00:13<00:00, 41.12it/s]\n",
            "[7 / 10]   Val: Loss = 13.38237, Accuracy = 96.03%: 100%|██████████| 13/13 [00:00<00:00, 28.00it/s]\n",
            "[8 / 10] Train: Loss = 4.47367, Accuracy = 97.18%: 100%|██████████| 572/572 [00:13<00:00, 43.08it/s]\n",
            "[8 / 10]   Val: Loss = 12.07159, Accuracy = 96.43%: 100%|██████████| 13/13 [00:00<00:00, 28.52it/s]\n",
            "[9 / 10] Train: Loss = 3.90730, Accuracy = 97.41%: 100%|██████████| 572/572 [00:13<00:00, 42.38it/s]\n",
            "[9 / 10]   Val: Loss = 13.01009, Accuracy = 95.90%: 100%|██████████| 13/13 [00:00<00:00, 28.72it/s]\n",
            "[10 / 10] Train: Loss = 3.63286, Accuracy = 97.52%: 100%|██████████| 572/572 [00:13<00:00, 43.27it/s]\n",
            "[10 / 10]   Val: Loss = 11.03546, Accuracy = 96.62%: 100%|██████████| 13/13 [00:00<00:00, 28.67it/s]\n"
          ]
        }
      ],
      "source": [
        "model = BidirectionalLSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind),\n",
        "    lstm_layers_count=3\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=10,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 0)\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=1,\n",
        "    batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvVkrBfk2TXd",
        "outputId": "6b7478b7-e870-4ba8-9b7d-3117e212924a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 1] Train: Loss = 3.47413, Accuracy = 97.74%: 100%|██████████| 72/72 [00:03<00:00, 18.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HPUuAPGhEGVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4f7465-a6ff-432a-a9b3-89ceceb9079e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 1] Train: Loss = 12.80029, Accuracy = 96.62%: 100%|██████████| 13/13 [00:00<00:00, 16.47it/s]\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 0)\n",
        "fit(model, criterion, optimizer, train_data=(X_val, y_val), epochs_count=1,\n",
        "    batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = 0)\n",
        "fit(model, criterion, optimizer, train_data=(X_test, y_test), epochs_count=1,\n",
        "    batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtDnsIav2Oc8",
        "outputId": "a27eb76e-884b-4099-9862-83a37c42deec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 1] Train: Loss = 9.93573, Accuracy = 96.69%: 100%|██████████| 28/28 [00:01<00:00, 19.17it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}