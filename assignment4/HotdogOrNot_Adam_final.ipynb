{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iWNeRNG2BzwW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import csv\n",
        "import urllib\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "from socket import timeout\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!pip3 install -q torch torchvision\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, SubsetRandomSampler, Sampler\n",
        "from torchvision import transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download train data\n",
        "!wget \"https://storage.googleapis.com/dlcourse_ai/train.zip\"\n",
        "!unzip -q \"train.zip\"\n",
        "\n",
        "train_folder = \"train_kaggle/\"\n",
        "# Count number of files in the train folder, should be 4603\n",
        "print('Number of files in the train folder', len(os.listdir(train_folder)))\n",
        "\n",
        "# Download test data\n",
        "!wget \"https://storage.googleapis.com/dlcourse_ai/test.zip\"\n",
        "!unzip -q \"test.zip\"\n",
        "\n",
        "test_folder = \"test_kaggle/\"\n",
        "# Count number of files in the test folder, should be 1150\n",
        "print('Number of files in the test folder', len(os.listdir(test_folder)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qb1COIHCZl2",
        "outputId": "b62449b3-1144-4202-b97e-0bdb90dae057"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-16 14:45:41--  https://storage.googleapis.com/dlcourse_ai/train.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 74.125.24.128, 142.250.4.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 562348083 (536M) [application/zip]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip           100%[===================>] 536.30M  22.1MB/s    in 25s     \n",
            "\n",
            "2022-12-16 14:46:08 (21.4 MB/s) - ‘train.zip’ saved [562348083/562348083]\n",
            "\n",
            "Number of files in the train folder 4603\n",
            "--2022-12-16 14:46:12--  https://storage.googleapis.com/dlcourse_ai/test.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.4.128, 142.251.10.128, 142.251.12.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.4.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 140788786 (134M) [application/zip]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>] 134.27M  23.4MB/s    in 6.9s    \n",
            "\n",
            "2022-12-16 14:46:19 (19.5 MB/s) - ‘test.zip’ saved [140788786/140788786]\n",
            "\n",
            "Number of files in the test folder 1150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "XpI4zWnhCcIY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HotdogOrNotDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.transform = transform\n",
        "        self.folder = folder\n",
        "        self.filenames = os.listdir(folder)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "    \n",
        "    def __getitem__(self, index):        \n",
        "        # TODO Implement getting item by index\n",
        "        # Hint: os.path.join is helpful!\n",
        "        y = 0\n",
        "        img_id = self.filenames[index]\n",
        "        img = Image.open(os.path.join(self.folder, img_id))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if img_id.startswith(\"frankfurter\") or img_id.startswith(\"chili-dog\") or img_id.startswith(\"hotdog\"):\n",
        "            y = 1\n",
        "        return img, y, img_id"
      ],
      "metadata": {
        "id": "DhCn22QGCjRD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, lets load the dataset\n",
        "train_dataset = HotdogOrNotDataset(\"train_kaggle\",\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize((224, 224)),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "                          transforms.RandomHorizontalFlip(),\n",
        "                          transforms.RandomAutocontrast()                       \n",
        "                       ])\n",
        "                      )"
      ],
      "metadata": {
        "id": "BUeFk4kQCxTw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "data_size = len(train_dataset)\n",
        "validation_fraction = .2\n",
        "\n",
        "\n",
        "val_split = int(np.floor((validation_fraction) * data_size))\n",
        "indices = list(range(data_size))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         sampler=val_sampler)"
      ],
      "metadata": {
        "id": "oD1hdrHMC0YK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler = None):\n",
        "    loss_history = []\n",
        "    train_history = []\n",
        "    val_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        model.train() # Enter train mode\n",
        "\n",
        "        loss_accum = 0\n",
        "        correct_samples = 0\n",
        "        total_samples = 0\n",
        "        for i_step, (x, y, _) in enumerate(train_loader):\n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "            prediction = model(x_gpu)\n",
        "            loss_value = loss(prediction, y_gpu)\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, indices = torch.max(prediction, 1)\n",
        "            correct_samples += torch.sum(indices == y_gpu)\n",
        "            total_samples += y_gpu.shape[0]\n",
        "\n",
        "            loss_accum += loss_value\n",
        "\n",
        "        ave_loss = loss_accum / i_step\n",
        "        train_accuracy = float(correct_samples) / total_samples\n",
        "        val_accuracy = compute_accuracy(model, val_loader)\n",
        "\n",
        "        loss_history.append(float(ave_loss))\n",
        "        train_history.append(train_accuracy)\n",
        "        val_history.append(val_accuracy)\n",
        "        print(\"epoch %d Average loss: %f, Train accuracy: %f, val accuracy: %f\" %\n",
        "                  (epoch+1, ave_loss, train_accuracy, val_accuracy))\n",
        "        if train_accuracy < 0.8:\n",
        "            return loss_history, train_history, val_history\n",
        "\n",
        "    return loss_history, train_history, val_history\n",
        "\n",
        "def compute_accuracy(model, loader):\n",
        "    \"\"\"\n",
        "    Computes accuracy on the dataset wrapped in a loader\n",
        "\n",
        "    Returns: accuracy as a float value between 0 and 1\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct_samples = 0\n",
        "    total_samples = 0\n",
        "    for i_step, (x, y, _) in enumerate(loader):\n",
        "        x_gpu = x.to(device)\n",
        "        y_gpu = y.to(device)\n",
        "        prediction = model(x_gpu)\n",
        "        _, indices = torch.max(prediction, 1)\n",
        "        correct_samples += torch.sum(indices == y_gpu)\n",
        "        total_samples += y_gpu.shape[0]\n",
        "\n",
        "    train_accuracy = float(correct_samples) / total_samples\n",
        "    return train_accuracy"
      ],
      "metadata": {
        "id": "Ol-rGdPTDCgR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "Hyperparams = namedtuple(\"Hyperparams\", ['lr', 'weight_decay', 'gamma', 'step_size'])\n",
        "RunResult = namedtuple(\"RunResult\", ['val_history', 'final_val_accuracy'])\n",
        "run_record = {}"
      ],
      "metadata": {
        "id": "VYdrDgM1ahge"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "for i in range(10):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model = model.to(device)\n",
        "    parameters = model.parameters()\n",
        "\n",
        "    lr = 10**np.random.uniform(-5, -3)\n",
        "    weight_decay = 10**np.random.uniform(-7, -2)\n",
        "    gamma = np.random.uniform(0.01, 0.4)\n",
        "    step_size = 4\n",
        "    print(f\"exp {i}\", \"lr =\", lr, \"(gamma, step_size) =\", f\"({gamma},{step_size})\", \"weight_decay =\", weight_decay)\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 5, scheduler)\n",
        "    hp = Hyperparams(lr=lr, weight_decay = weight_decay, gamma=gamma, step_size = step_size)\n",
        "    rr = RunResult(val_history=val_history, final_val_accuracy=val_history[-1])\n",
        "    run_record[hp] = rr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_AGI3IbDYzZ",
        "outputId": "aaa23049-8a9e-4fc7-e063-31fe5741ad45"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 Average loss: 0.383189, Train accuracy: 0.834374, val accuracy: 0.927174\n",
            "epoch 2 Average loss: 0.192848, Train accuracy: 0.934564, val accuracy: 0.940217\n",
            "epoch 3 Average loss: 0.129341, Train accuracy: 0.957372, val accuracy: 0.954348\n",
            "epoch 4 Average loss: 0.098522, Train accuracy: 0.970405, val accuracy: 0.960870\n",
            "epoch 5 Average loss: 0.092499, Train accuracy: 0.972034, val accuracy: 0.951087\n",
            "exp 1 lr = 1.2846401670472579e-05 (gamma, step_size) = (0.3899565851164549,4) weight_decay = 0.00016644993053753927\n",
            "epoch 1 Average loss: 0.393942, Train accuracy: 0.838175, val accuracy: 0.909783\n",
            "epoch 2 Average loss: 0.194745, Train accuracy: 0.939452, val accuracy: 0.938043\n",
            "epoch 3 Average loss: 0.147225, Train accuracy: 0.951670, val accuracy: 0.954348\n",
            "epoch 4 Average loss: 0.116022, Train accuracy: 0.961988, val accuracy: 0.941304\n",
            "epoch 5 Average loss: 0.104817, Train accuracy: 0.966332, val accuracy: 0.948913\n",
            "exp 2 lr = 1.3791176265215666e-05 (gamma, step_size) = (0.30163979640615524,4) weight_decay = 5.9352436069761535e-05\n",
            "epoch 1 Average loss: 0.345415, Train accuracy: 0.850122, val accuracy: 0.925000\n",
            "epoch 2 Average loss: 0.182640, Train accuracy: 0.937008, val accuracy: 0.942391\n",
            "epoch 3 Average loss: 0.140847, Train accuracy: 0.948955, val accuracy: 0.944565\n",
            "epoch 4 Average loss: 0.115625, Train accuracy: 0.961444, val accuracy: 0.950000\n",
            "epoch 5 Average loss: 0.108821, Train accuracy: 0.963345, val accuracy: 0.955435\n",
            "exp 3 lr = 0.0004173661021355521 (gamma, step_size) = (0.08962495807561477,4) weight_decay = 1.1725660795879536e-05\n",
            "epoch 1 Average loss: 0.292867, Train accuracy: 0.882161, val accuracy: 0.930435\n",
            "epoch 2 Average loss: 0.146076, Train accuracy: 0.942438, val accuracy: 0.845652\n",
            "epoch 3 Average loss: 0.104233, Train accuracy: 0.959544, val accuracy: 0.908696\n",
            "epoch 4 Average loss: 0.059313, Train accuracy: 0.978822, val accuracy: 0.960870\n",
            "epoch 5 Average loss: 0.037506, Train accuracy: 0.988325, val accuracy: 0.960870\n",
            "exp 4 lr = 1.215302965232027e-05 (gamma, step_size) = (0.18663531740436823,4) weight_decay = 7.9182787349908e-05\n",
            "epoch 1 Average loss: 0.381529, Train accuracy: 0.844692, val accuracy: 0.910870\n",
            "epoch 2 Average loss: 0.205720, Train accuracy: 0.929134, val accuracy: 0.929348\n",
            "epoch 3 Average loss: 0.152032, Train accuracy: 0.947869, val accuracy: 0.942391\n",
            "epoch 4 Average loss: 0.123764, Train accuracy: 0.959815, val accuracy: 0.952174\n",
            "epoch 5 Average loss: 0.121276, Train accuracy: 0.960087, val accuracy: 0.944565\n",
            "exp 5 lr = 0.0007897484647105956 (gamma, step_size) = (0.27730418394394224,4) weight_decay = 2.009206333891233e-07\n",
            "epoch 1 Average loss: 0.353322, Train accuracy: 0.862884, val accuracy: 0.905435\n",
            "epoch 2 Average loss: 0.185094, Train accuracy: 0.923704, val accuracy: 0.838043\n",
            "epoch 3 Average loss: 0.184793, Train accuracy: 0.926147, val accuracy: 0.911957\n",
            "epoch 4 Average loss: 0.098896, Train accuracy: 0.964703, val accuracy: 0.936957\n",
            "epoch 5 Average loss: 0.045539, Train accuracy: 0.985610, val accuracy: 0.942391\n",
            "exp 6 lr = 1.1218439346675023e-05 (gamma, step_size) = (0.18689580996990532,4) weight_decay = 7.197321181145895e-07\n",
            "epoch 1 Average loss: 0.440775, Train accuracy: 0.808037, val accuracy: 0.904348\n",
            "epoch 2 Average loss: 0.226547, Train accuracy: 0.927233, val accuracy: 0.934783\n",
            "epoch 3 Average loss: 0.154911, Train accuracy: 0.952484, val accuracy: 0.954348\n",
            "epoch 4 Average loss: 0.130178, Train accuracy: 0.954385, val accuracy: 0.953261\n",
            "epoch 5 Average loss: 0.129873, Train accuracy: 0.956829, val accuracy: 0.947826\n",
            "exp 7 lr = 8.123531813602789e-05 (gamma, step_size) = (0.36498308359842513,4) weight_decay = 0.0002682271373776154\n",
            "epoch 1 Average loss: 0.236045, Train accuracy: 0.901982, val accuracy: 0.915217\n",
            "epoch 2 Average loss: 0.089501, Train accuracy: 0.969862, val accuracy: 0.947826\n",
            "epoch 3 Average loss: 0.051134, Train accuracy: 0.982623, val accuracy: 0.952174\n",
            "epoch 4 Average loss: 0.023928, Train accuracy: 0.991854, val accuracy: 0.956522\n",
            "epoch 5 Average loss: 0.019140, Train accuracy: 0.995384, val accuracy: 0.965217\n",
            "exp 8 lr = 0.00018969868389929093 (gamma, step_size) = (0.3538300995524191,4) weight_decay = 0.005857003576951157\n",
            "epoch 1 Average loss: 0.237644, Train accuracy: 0.903068, val accuracy: 0.923913\n",
            "epoch 2 Average loss: 0.094089, Train accuracy: 0.963888, val accuracy: 0.944565\n",
            "epoch 3 Average loss: 0.073827, Train accuracy: 0.972848, val accuracy: 0.915217\n",
            "epoch 4 Average loss: 0.049122, Train accuracy: 0.982351, val accuracy: 0.954348\n",
            "epoch 5 Average loss: 0.018931, Train accuracy: 0.994298, val accuracy: 0.956522\n",
            "exp 9 lr = 0.00014757051437283905 (gamma, step_size) = (0.2606052680262173,4) weight_decay = 0.0014755697881430009\n",
            "epoch 1 Average loss: 0.225255, Train accuracy: 0.902525, val accuracy: 0.935870\n",
            "epoch 2 Average loss: 0.090445, Train accuracy: 0.965246, val accuracy: 0.946739\n",
            "epoch 3 Average loss: 0.040735, Train accuracy: 0.987239, val accuracy: 0.944565\n",
            "epoch 4 Average loss: 0.033025, Train accuracy: 0.988868, val accuracy: 0.964130\n",
            "epoch 5 Average loss: 0.017324, Train accuracy: 0.994841, val accuracy: 0.966304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = sorted(list(run_record.items()), key=lambda x: x[1].final_val_accuracy)[::-1]\n",
        "for a, b in result:\n",
        "    print(a, b.final_val_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_43NpVQ9bjdP",
        "outputId": "5d4ba48a-1c87-4119-edca-4d6ba2232953"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparams(lr=0.00014757051437283905, weight_decay=0.0014755697881430009, gamma=0.2606052680262173, step_size=4) 0.966304347826087\n",
            "Hyperparams(lr=8.123531813602789e-05, weight_decay=0.0002682271373776154, gamma=0.36498308359842513, step_size=4) 0.9652173913043478\n",
            "Hyperparams(lr=0.0004173661021355521, weight_decay=1.1725660795879536e-05, gamma=0.08962495807561477, step_size=4) 0.9608695652173913\n",
            "Hyperparams(lr=0.00018969868389929093, weight_decay=0.005857003576951157, gamma=0.3538300995524191, step_size=4) 0.9565217391304348\n",
            "Hyperparams(lr=0.0003284812869193094, weight_decay=3.9847548290583244e-05, gamma=0.37111623523091136, step_size=4) 0.9565217391304348\n",
            "Hyperparams(lr=0.00017733133063054424, weight_decay=1.2429609308571704e-07, gamma=0.10685991276607926, step_size=4) 0.9565217391304348\n",
            "Hyperparams(lr=1.3791176265215666e-05, weight_decay=5.9352436069761535e-05, gamma=0.30163979640615524, step_size=4) 0.9554347826086956\n",
            "Hyperparams(lr=0.0004207723628995787, weight_decay=1.2083459824318078e-07, gamma=0.13208889858228565, step_size=4) 0.9554347826086956\n",
            "Hyperparams(lr=3.392956645879145e-05, weight_decay=0.0003814608966369946, gamma=0.003207696512618674, step_size=4) 0.9543478260869566\n",
            "Hyperparams(lr=2.3840189608615706e-05, weight_decay=0.0030762981069185286, gamma=0.4250854479572248, step_size=4) 0.9543478260869566\n",
            "Hyperparams(lr=1.660070638829644e-05, weight_decay=0.004219256000599387, gamma=0.2563409708823277, step_size=4) 0.9510869565217391\n",
            "Hyperparams(lr=1.2846401670472579e-05, weight_decay=0.00016644993053753927, gamma=0.3899565851164549, step_size=4) 0.9489130434782609\n",
            "Hyperparams(lr=1.1218439346675023e-05, weight_decay=7.197321181145895e-07, gamma=0.18689580996990532, step_size=4) 0.9478260869565217\n",
            "Hyperparams(lr=0.0003650685579484342, weight_decay=3.0570202300778876e-07, gamma=0.3829933438750959, step_size=4) 0.9456521739130435\n",
            "Hyperparams(lr=1.215302965232027e-05, weight_decay=7.9182787349908e-05, gamma=0.18663531740436823, step_size=4) 0.9445652173913044\n",
            "Hyperparams(lr=0.0007897484647105956, weight_decay=2.009206333891233e-07, gamma=0.27730418394394224, step_size=4) 0.9423913043478261\n",
            "Hyperparams(lr=0.001925968565217448, weight_decay=6.67085705684225e-06, gamma=0.22724177876138885, step_size=4) 0.7391304347826086\n",
            "Hyperparams(lr=0.0020670961216456107, weight_decay=0.0009691508683187791, gamma=0.5210464727648292, step_size=4) 0.7152173913043478\n",
            "Hyperparams(lr=0.05750785484626106, weight_decay=0.0003373077698040677, gamma=0.5695204159085349, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.0009475250111384922, weight_decay=0.1064920277165823, gamma=0.276700140752346, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.008550952195817607, weight_decay=0.005406021681021894, gamma=0.08306129599763658, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.06992583528318612, weight_decay=0.022400885758823347, gamma=0.4396716022006817, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.04096141129375677, weight_decay=0.03994169589461165, gamma=0.42053919674952345, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.006719723807046305, weight_decay=0.06361822168729567, gamma=0.43066082298425623, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.008808775264592061, weight_decay=4.1544887988193536e-05, gamma=0.3667087639135589, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.0033125276641900155, weight_decay=0.014083881603515003, gamma=0.4135089556068997, step_size=4) 0.6793478260869565\n",
            "Hyperparams(lr=0.0034063605465388903, weight_decay=0.0001927509784364335, gamma=0.2658356173982526, step_size=4) 0.6782608695652174\n",
            "Hyperparams(lr=0.004977776212872, weight_decay=1.082209864233094e-07, gamma=0.28633030128924986, step_size=4) 0.675\n",
            "Hyperparams(lr=0.02144507687826511, weight_decay=3.44365200920584e-05, gamma=0.5181848527779696, step_size=4) 0.6728260869565217\n",
            "Hyperparams(lr=0.056709389954527144, weight_decay=8.01135240005423e-05, gamma=0.24140097314239964, step_size=4) 0.6684782608695652\n",
            "Hyperparams(lr=0.04638880730301159, weight_decay=0.001725643232952686, gamma=0.22358239602726107, step_size=4) 0.32065217391304346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "for a, b in result[:6]:\n",
        "  x.append(a.gamma)\n",
        "sorted(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYmrsRF4j06x",
        "outputId": "aca3f895-4fcc-47c4-c485-9a825a0aa0e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.003207696512618674,\n",
              " 0.10685991276607926,\n",
              " 0.13208889858228565,\n",
              " 0.37111623523091136,\n",
              " 0.3829933438750959,\n",
              " 0.4250854479572248]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "parameters = model.parameters()\n",
        "\n",
        "lr = 0.00014757051437283905\n",
        "weight_decay = 0.0014755697881430009\n",
        "gamma = 0.2606052680262173\n",
        "step_size = 4\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, 4, scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "s0KGLspUrZ5p",
        "outputId": "6147db72-4018-4ba4-fe06-43fe19016497"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 Average loss: 0.237348, Train accuracy: 0.901439, val accuracy: 0.945652\n",
            "epoch 2 Average loss: 0.091412, Train accuracy: 0.967689, val accuracy: 0.886957\n",
            "epoch 3 Average loss: 0.079242, Train accuracy: 0.968504, val accuracy: 0.945652\n",
            "epoch 4 Average loss: 0.035452, Train accuracy: 0.986696, val accuracy: 0.963043\n",
            "epoch 5 Average loss: 0.019188, Train accuracy: 0.995656, val accuracy: 0.957609\n",
            "epoch 6 Average loss: 0.011454, Train accuracy: 0.997013, val accuracy: 0.957609\n",
            "epoch 7 Average loss: 0.007588, Train accuracy: 0.998099, val accuracy: 0.959783\n",
            "epoch 8 Average loss: 0.007241, Train accuracy: 0.998914, val accuracy: 0.960870\n",
            "epoch 9 Average loss: 0.007703, Train accuracy: 0.998371, val accuracy: 0.964130\n",
            "epoch 10 Average loss: 0.005236, Train accuracy: 0.999728, val accuracy: 0.961957\n",
            "epoch 11 Average loss: 0.003747, Train accuracy: 0.999728, val accuracy: 0.957609\n",
            "epoch 12 Average loss: 0.004214, Train accuracy: 0.999728, val accuracy: 0.960870\n",
            "epoch 13 Average loss: 0.004285, Train accuracy: 0.999728, val accuracy: 0.959783\n",
            "epoch 14 Average loss: 0.004841, Train accuracy: 0.998914, val accuracy: 0.958696\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ec18196be6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-5c319338f716>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcorrect_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0my_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-07a7b8079ae4>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"frankfurter\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chili-dog\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hotdog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \"\"\"\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1884\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SubsetSampler(Sampler):\n",
        "    r\"\"\"Samples elements with given indices sequentially\n",
        "\n",
        "    Arguments:\n",
        "        indices (ndarray): indices of the samples to take\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, indices):\n",
        "        self.indices = indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in range(len(self.indices)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "    \n",
        "    \n",
        "def evaluate_model(model, dataset, indices):\n",
        "    \"\"\"\n",
        "    Computes predictions and ground truth labels for the indices of the dataset\n",
        "    \n",
        "    Returns: \n",
        "    predictions: np array of ints - model predictions\n",
        "    grount_truth: np array of ints - actual labels of the dataset\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    ground_truth = []\n",
        "    sampler = SubsetSampler(indices)\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                           sampler=sampler)\n",
        "    for i_step, (x, y, _) in enumerate(loader):\n",
        "        prediction = model(x)\n",
        "        _, ind = torch.max(prediction, 1)\n",
        "        predictions.extend(ind)\n",
        "        ground_truth.extend(y)\n",
        "\n",
        "    return predictions, ground_truth\n",
        "\n",
        "model.to('cpu')\n",
        "predictions, gt = evaluate_model(model, train_dataset, val_indices)\n",
        "\n",
        "def binary_classification_metrics(prediction, ground_truth):\n",
        "    if type(prediction) == type(list()):\n",
        "      prediction = np.array(prediction)\n",
        "    if type(ground_truth) == type(list()):\n",
        "      ground_truth = np.array(ground_truth)\n",
        "    precision = np.sum(prediction & ground_truth) / np.sum(prediction)\n",
        "    recall = np.sum(prediction & ground_truth) / np.sum(ground_truth)\n",
        "    f1 = 2 / (1/precision + 1/recall)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "\n",
        "precision, recall, f1 = binary_classification_metrics(predictions, gt)\n",
        "print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (f1, precision, recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8Ui8aXir6UV",
        "outputId": "0cd8c484-1a67-4a9b-91a5-879989af2acf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.937, P: 0.945, R: 0.929\n"
          ]
        }
      ]
    }
  ]
}